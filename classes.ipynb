{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arstotrix/2kursach/blob/master/classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b_wx0tk0guI",
        "colab_type": "text"
      },
      "source": [
        "Дисклеймер 1: код говно\n",
        "\n",
        "Дисклеймер 2: я закончила его писать 31 декабря в час ночи (а в моём городе щас вообще пять утра) так что может быть это не совсем считать опозданием? (ну пожалуйста, тут и так баллов немного)\n",
        "\n",
        "Дисклеймер 3: под \"написать документацию\" подразумевались \"\"\" \"\"\" как на семинаре? если да, то это сделано...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OBTBot3_Kr2",
        "colab_type": "code",
        "outputId": "e4d302d4-c271-4c2d-fbf6-c277f6649e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install pymorphy2\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.stem import WordNetLemmatizer  \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64whTY49kL19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parts_of_speech = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
        "nltk_parts_of_speech = {\"CC\": \"CCONJ\", \"CD\"\t: 'NUM', \"DT\"\t: 'DET', \"EX\"\t: 'X', \"FW\"\t: 'X', \"IN\"\t: 'ADP',\"JJ\"\t: 'ADJ', \"JJR\"\t: 'ADJ',\"JJS\"\t: 'ADJ', \"LS\"\t: 'SYM',\"MD\"\t: 'AUX', \"NN\"\t: \"NOUN\",\"NNS\"\t: \"NOUN\", \"NNP\" : \"PROPN\",\"NNPS\" : \"PROPN\", \"PDT\"\t: 'DET',\"POS\"\t: 'X', \"PRP\"\t: 'PRON',\"PRPS\"\t: 'PRON', \"RB\"\t: 'ADV',\"RBR\"\t: 'ADV', \"RBS\"\t: 'ADV',\"RP\"\t: 'PART', \"TO\"\t: 'ADP',\"UH\"\t: 'INTJ', \"VB\"\t: 'VERB',\"VBD\"\t: 'VERB', \"VBG\"\t: 'VERB',\"VBN\"\t: 'VERB', \"VBP\"\t: 'VERB',\"VBZ\"\t: 'VERB', \"WDT\"\t: 'DET',\"WP\"\t: 'PRON', \"WPS\"\t: 'PRON',\"WRB\"\t: 'ADV'}\n",
        "pymorphy2_parts_of_speech = {\"ADJF\":\"ADJ\", \"ADJS\":\"ADJ\", \"COMP\":\"ADJ\" , \"INFN\":\"VERB\", \"PRTF\":\"VERB\" , \"PRTS\":\"VERB\" , \"GRND\":\"VERB\", \"NUM\":\"NUM\", \"ADVB\":\"ADV\", \"NPRO\":\"PRON\", \"PRED\":\"VERB\", \"PREP\":\"ADP\", \"CONJ\":\"CCONJ\", \"PRCL\":\"PART\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlpWPiehTUwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnglishSentence:\n",
        "  def __init__(self, sentence, tokens, tags):\n",
        "        \"\"\"\n",
        "        Constructor\n",
        "        \"\"\"\n",
        "        self.sentence = sentence\n",
        "        self.tokens = tokens\n",
        "        self.tags = tags\n",
        "\n",
        "  def get_words(self):\n",
        "    \"\"\"\n",
        "    Prints out the sentence in words\n",
        "    \"\"\"\n",
        "    print(tokens)\n",
        "\n",
        "  def get_lemmas(self):\n",
        "    \"\"\"\n",
        "    Prints out the lemmatized sentence\n",
        "    \"\"\"\n",
        "    lemmas = []\n",
        "    for token in tokens:\n",
        "      lemmas.append(lemmatizer.lemmatize(token))\n",
        "    print(lemmas)\n",
        "  \n",
        "  \n",
        "  def get_pos(self, pos):\n",
        "    \"\"\"\n",
        "    Receives a part of speech and searches for it in the sencence\n",
        "    \"\"\"\n",
        "    partsos = []\n",
        "    print(tags)\n",
        "    for tag in tags:\n",
        "      if tag[1] == pos:\n",
        "        partsos.append(tag[0])\n",
        "    if partsos = []:\n",
        "      partsos = 'Увы, мы не нашли таких частей речи.'  \n",
        "    print(partsos)\n",
        "\n",
        "  def check_affirm(self):\n",
        "    \"\"\"\n",
        "    Determines the type of sentence judging by the last symbol of the sentence\n",
        "    \"\"\"\n",
        "    if tokens[-1] == '!':\n",
        "      print('Восклицательное!')\n",
        "    elif tokens[-1] == '?':\n",
        "      print('Вопросительное?')\n",
        "    else:\n",
        "      print('Утвердительное')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pm58jQIDijR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RussianSentence:\n",
        "  def __init__(self, sentence, tokens, tags):\n",
        "        \"\"\"\n",
        "        Constructor\n",
        "        \"\"\"\n",
        "        self.sentence = sentence\n",
        "        self.tokens = tokens\n",
        "        self.tags = tags\n",
        "\n",
        "  def get_words(self):\n",
        "    \"\"\"\n",
        "    Prints out the sentence in words\n",
        "    \"\"\"\n",
        "    print(tokens)\n",
        "\n",
        "  def get_lemmas(self):\n",
        "    \"\"\"\n",
        "    Prints out the lemmatized sentence\n",
        "    \"\"\"\n",
        "    lemmas = []\n",
        "    for token in tagged:\n",
        "      lemmas.append(token[2])\n",
        "    print(lemmas)\n",
        "  \n",
        "  \n",
        "  def get_pos(self, pos):\n",
        "    \"\"\"\n",
        "    Receives a part of speech and searches for it in the sencence\n",
        "    \"\"\"\n",
        "    partsos = []\n",
        "    tags = []\n",
        "    for t in tagged:\n",
        "      octag = str(t[1]).split(\",\")[0]\n",
        "      tag = [t[0], octag]\n",
        "      #print(tag)\n",
        "      if octag in pymorphy2_parts_of_speech:\n",
        "        try:\n",
        "          tag[1] = pymorphy2_parts_of_speech[octag]\n",
        "        except KeyError:\n",
        "          tag[1]= 'SYM'\n",
        "      #print(tag)\n",
        "      tags.append(tag)\n",
        "    for tag in tags:\n",
        "      if tag[1] == pos:\n",
        "        partsos.append(tag[0])\n",
        "    if partsos == []:\n",
        "      partsos = 'Увы, мы не нашли таких частей речи.'\n",
        "    print(partsos)\n",
        "\n",
        "  def check_affirm(self):\n",
        "    \"\"\"\n",
        "    Determines the type of sentence judging by the last symbol of the sentence\n",
        "    \"\"\"\n",
        "    if sentence[-1] == '!':\n",
        "      print('Восклицательное!')\n",
        "    elif sentence[-1] == '?':\n",
        "      print('Вопросительное?')\n",
        "    else:\n",
        "      print('Утвердительное')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrWpCz-drhzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b74a4028-5d46-48a7-e300-2eb822d35ffa"
      },
      "source": [
        "lang = input('На каком языке предложение? RU/EN: ')\n",
        "sentence = input('Введите ваше предложение: ')\n",
        "pos = input('Введите часть речи из списка: ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X: ')\n",
        "if pos not in parts_of_speech:\n",
        "  print('А вы бунтарь! Ладно, ищем глаголы.')\n",
        "  pos = 'VERB'\n",
        "if lang.lower == 'EN':\n",
        "  tokens = nltk.word_tokenize(sentence)\n",
        "  tagged = nltk.pos_tag(tokens)\n",
        "  tags = []\n",
        "  for t in tagged:\n",
        "    tag = [t[0]]\n",
        "    try:\n",
        "      tag.append(nltk_parts_of_speech[t[1]])\n",
        "    except KeyError:\n",
        "      tag.append('SYM')\n",
        "    tags.append(tag)\n",
        "  print(tags)\n",
        "  ensent1 = EnglishSentence(sentence, tokens, tags)\n",
        "  ensent1.get_words()\n",
        "  ensent1.get_lemmas()\n",
        "  ensent1.get_pos(pos)\n",
        "  ensent1.check_affirm()\n",
        "else:\n",
        "  puncts = '?!-,.:;'\n",
        "  tokens = []\n",
        "  tagged = []\n",
        "  words = sentence.lower().split()\n",
        "  for i, word in enumerate(words):\n",
        "    word = word.strip(puncts)\n",
        "    tokens.append(word)\n",
        "    tagged.append(morph.parse(word)[0])\n",
        "  rusent1 = RussianSentence(sentence, tokens, tagged) \n",
        "  rusent1.get_words()\n",
        "  rusent1.get_lemmas()\n",
        "  rusent1.get_pos('NOUN')\n",
        "  rusent1.check_affirm()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "На каком языке предложение? RU/ENRU\n",
            "Введите ваше предложение: Маша и Медведь это плохой мультик!\n",
            "Введите часть речи из списка: ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, XNOUN\n",
            "['маша', 'и', 'медведь', 'это', 'плохой', 'мультик']\n",
            "['маша', 'и', 'медведь', 'это', 'плохой', 'мультик']\n",
            "['мультик']\n",
            "Восклицательное!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}